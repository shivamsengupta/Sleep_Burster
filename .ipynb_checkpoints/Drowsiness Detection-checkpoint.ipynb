{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52148f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version:\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f64ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4870aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dlib-19.22.99-cp38-cp38-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d1ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install playsound==1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baa43a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DON'T MOVE YOUR HEAD TOO RAPIDLY !!!\n",
      "DON'T MOVE YOUR HEAD TOO RAPIDLY !!!\n",
      "DON'T MOVE YOUR HEAD TOO RAPIDLY !!!\n",
      "DON'T MOVE YOUR HEAD TOO RAPIDLY !!!\n",
      "DON'T MOVE YOUR HEAD TOO RAPIDLY !!!\n",
      "DON'T MOVE YOUR HEAD TOO RAPIDLY !!!\n",
      "DON'T MOVE YOUR HEAD TOO RAPIDLY !!!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import playsound\n",
    "import math\n",
    "import time\n",
    "from termcolor import colored, cprint\n",
    "cap=cv2.VideoCapture(0)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor= dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "(mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]\n",
    "sleep=0\n",
    "drowsy=0\n",
    "active=0\n",
    "yawn_countdown = 0\n",
    "status=\"\"\n",
    "color=(0,0,0)\n",
    "path=\"alarm2(trimmed).wav\"\n",
    "def compute(ptA,ptB):\n",
    "    dist=np.linalg.norm(ptA-ptB)\n",
    "    return dist\n",
    "def blinked(a,b,c,d,e,f):\n",
    "    up=compute(b,d)+compute(c,e)\n",
    "    down=compute(a,f)\n",
    "    ratio=up/(2.0*down)\n",
    "    if(ratio>0.22):\n",
    "        return 2\n",
    "    elif(ratio>0.15 and ratio<=0.22):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def yawn(mouth):\n",
    "    return ((euclideanDist(mouth[2], mouth[10])+euclideanDist(mouth[4], mouth[8]))/(2*euclideanDist(mouth[0], mouth[6])))\n",
    "def euclideanDist(a, b):\n",
    "    return (math.sqrt(math.pow(a[0]-b[0], 2)+math.pow(a[1]-b[1], 2)))\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        \n",
    "        ret,frame=cap.read()\n",
    "            \n",
    "        gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        faces = detector(gray)\n",
    "        shape = face_utils.shape_to_np(predictor(frame, faces[0]))\n",
    "    \n",
    "        for face in faces:\n",
    "            x1=face.left()\n",
    "            y1=face.top()\n",
    "            x2=face.right()\n",
    "            y2=face.bottom()\n",
    "        \n",
    "            face_frame=frame.copy()\n",
    "            cv2.rectangle(face_frame, (x1,y1),(x2,y2),(0,255,0),2)\n",
    "        \n",
    "            landmarks=predictor(gray,face)\n",
    "            landmarks=face_utils.shape_to_np(landmarks)\n",
    "        \n",
    "            left_blink=blinked(landmarks[36],landmarks[37],landmarks[38],landmarks[41],landmarks[40],landmarks[39])\n",
    "            right_blink=blinked(landmarks[42],landmarks[43],landmarks[44],landmarks[47],landmarks[46],landmarks[45])\n",
    "        \n",
    "            \n",
    "            if(yawn_countdown>=50):\n",
    "                cv2.putText(frame,\"YOU ARE ABOUT TO SLEEP !!!\",(150,40),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,0,255),2)\n",
    "            \n",
    "            \n",
    "            if(yawn(shape[mStart:mEnd])>0.6):\n",
    "                cv2.putText(frame,\"YAWN DETECTED !!!\",(200,200),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,0,255),2)\n",
    "                yawn_countdown+=1\n",
    "       \n",
    "        \n",
    "        \n",
    "            if(left_blink==0 or right_blink==0):\n",
    "                sleep+=1\n",
    "                drowsy=0\n",
    "                active=0\n",
    "                if(sleep>8):\n",
    "                    status=\"SLEEPING !!!\"\n",
    "                    color=(0,0,255)\n",
    "                    playsound.playsound(path)\n",
    "            elif(left_blink==1 or right_blink==1):\n",
    "                sleep=0\n",
    "                drowsy+=1\n",
    "                active=0\n",
    "                if(drowsy>6):\n",
    "                    status=\"DROWSY !!!\"\n",
    "                    color=(255,0,0)\n",
    "            else:\n",
    "                sleep=0\n",
    "                drowsy=0\n",
    "                active+=1\n",
    "                if(active>6):\n",
    "                    status=\"ACTIVE :)\"\n",
    "                    color=(0,255,0)\n",
    "            cv2.putText(frame,status,(100,100),cv2.FONT_HERSHEY_SIMPLEX,1.2,color,3)\n",
    "        \n",
    "            for n in range(0,68):\n",
    "                (x,y)=landmarks[n]\n",
    "                cv2.circle(face_frame,(x,y),1,(255,255,255),-1)\n",
    "    except Exception as e:\n",
    "        cv2.putText(frame,\"DON'T MOVE YOUR HEAD TOO RAPIDLY !!!\",(80,200),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,0,255),3)\n",
    "        time.sleep(0.2)\n",
    "        print(\"DON'T MOVE YOUR HEAD TOO RAPIDLY !!!\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    cv2.imshow(\"Frame: \",frame)\n",
    "    cv2.imshow(\"Result of detector: \",face_frame)\n",
    "    key=cv2.waitKey(1)\n",
    "    if key==27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c83172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddb3c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f189e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c469abbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7e160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8594250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4cf053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc8d1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f26881d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a388d8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f19a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfacefa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ff87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad54ee79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a304fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3f7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe69a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761c728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97616820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e93f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b8ae0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e7843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ffc4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d6dcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b83d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f74c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d6dac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6e51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68cad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41928fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828462e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7f187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e45295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc98505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d28d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033151e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8221a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a85b4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import dlib\n",
    "# import pyttsx3\n",
    "# from scipy.spatial import distance\n",
    "\n",
    "# # INITIALIZING THE pyttsx3 SO THAT \n",
    "# # ALERT AUDIO MESSAGE CAN BE DELIVERED\n",
    "# engine = pyttsx3.init()\n",
    "\n",
    "# # SETTING UP OF CAMERA TO 1 YOU CAN\n",
    "# # EVEN CHOOSE 0 IN PLACE OF 1\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # FACE DETECTION OR MAPPING THE FACE TO\n",
    "# # GET THE Eye AND EYES DETECTED\n",
    "# face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# # PUT THE LOCATION OF .DAT FILE (FILE FOR\n",
    "# # PREDECTING THE LANDMARKS ON FACE )\n",
    "# dlib_facelandmark = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# # FUNCTION CALCULATING THE ASPECT RATIO FOR\n",
    "# # THE Eye BY USING EUCLIDEAN DISTANCE FUNCTION\n",
    "# def Detect_Eye(eye):\n",
    "# \tpoi_A = distance.euclidean(eye[1], eye[5])\n",
    "# \tpoi_B = distance.euclidean(eye[2], eye[4])\n",
    "# \tpoi_C = distance.euclidean(eye[0], eye[3])\n",
    "# \taspect_ratio_Eye = (poi_A+poi_B)/(2*poi_C)\n",
    "# \treturn aspect_ratio_Eye\n",
    "\n",
    "\n",
    "# # MAIN LOOP IT WILL RUN ALL THE UNLESS AND \n",
    "# # UNTIL THE PROGRAM IS BEING KILLED BY THE USER\n",
    "# while True:\n",
    "# \tnull, frame = cap.read()\n",
    "# \tgray_scale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# \tfaces = face_detector(gray_scale)\n",
    "\n",
    "# \tfor face in faces:\n",
    "# \t\tface_landmarks = dlib_facelandmark(gray_scale, face)\n",
    "# \t\tleftEye = [] \n",
    "# \t\trightEye = [] \n",
    "\n",
    "# \t\t# THESE ARE THE POINTS ALLOCATION FOR THE \n",
    "# \t\t# LEFT EYES IN .DAT FILE THAT ARE FROM 42 TO 47\n",
    "# \t\tfor n in range(42, 48):\n",
    "# \t\t\tx = face_landmarks.part(n).x\n",
    "# \t\t\ty = face_landmarks.part(n).y\n",
    "# \t\t\trightEye.append((x, y))\n",
    "# \t\t\tnext_point = n+1\n",
    "# \t\t\tif n == 47:\n",
    "# \t\t\t\tnext_point = 42\n",
    "# \t\t\tx2 = face_landmarks.part(next_point).x\n",
    "# \t\t\ty2 = face_landmarks.part(next_point).y\n",
    "# \t\t\tcv2.line(frame, (x, y), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "# \t\t# THESE ARE THE POINTS ALLOCATION FOR THE \n",
    "# \t\t# RIGHT EYES IN .DAT FILE THAT ARE FROM 36 TO 41\n",
    "# \t\tfor n in range(36, 42):\n",
    "# \t\t\tx = face_landmarks.part(n).x\n",
    "# \t\t\ty = face_landmarks.part(n).y\n",
    "# \t\t\tleftEye.append((x, y))\n",
    "# \t\t\tnext_point = n+1\n",
    "# \t\t\tif n == 41:\n",
    "# \t\t\t\tnext_point = 36\n",
    "# \t\t\tx2 = face_landmarks.part(next_point).x\n",
    "# \t\t\ty2 = face_landmarks.part(next_point).y\n",
    "# \t\t\tcv2.line(frame, (x, y), (x2, y2), (255, 255, 0), 1)\n",
    "\n",
    "# \t\t# CALCULATING THE ASPECT RATIO FOR LEFT \n",
    "# \t\t# AND RIGHT EYE\n",
    "# \t\tright_Eye = Detect_Eye(rightEye)\n",
    "# \t\tleft_Eye = Detect_Eye(leftEye)\n",
    "# \t\tEye_Rat = (left_Eye+right_Eye)/2\n",
    "\n",
    "# \t\t# NOW ROUND OF THE VALUE OF AVERAGE MEAN \n",
    "# \t\t# OF RIGHT AND LEFT EYES\n",
    "# \t\tEye_Rat = round(Eye_Rat, 2)\n",
    "\n",
    "# \t\t# THIS VALUE OF 0.25 (YOU CAN EVEN CHANGE IT) \n",
    "# \t\t# WILL DECIDE WHETHER THE PERSONS'S EYES ARE CLOSE OR NOT\n",
    "# \t\tif Eye_Rat < 0.25:\n",
    "# \t\t\tcv2.putText(frame, \"DROWSINESS DETECTED\", (50, 100),\n",
    "# \t\t\t\t\t\tcv2.FONT_HERSHEY_PLAIN, 2, (21, 56, 210), 3)\n",
    "# \t\t\tcv2.putText(frame, \"Alert!!!! WAKE UP DUDE\", (50, 450),\n",
    "# \t\t\t\t\t\tcv2.FONT_HERSHEY_PLAIN, 2, (21, 56, 212), 3)\n",
    "\n",
    "# \t\t\t# CALLING THE AUDIO FUNCTION OF TEXT TO \n",
    "# \t\t\t# AUDIO FOR ALERTING THE PERSON\n",
    "# \t\t\tengine.say(\"Alert!!!! WAKE UP DUDE\")\n",
    "# \t\t\tengine.runAndWait()\n",
    "\n",
    "# \tcv2.imshow(\"Drowsiness DETECTOR IN OPENCV2\", frame)\n",
    "# \tkey = cv2.waitKey(1)\n",
    "# \tif key == 27:\n",
    "# \t\tbreak\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d82f8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyttsx3\n",
    "# e=pyttsx3.init()\n",
    "# voice = e.getProperty('voices')[1]\n",
    "# engine.setProperty('voice',voice.id)\n",
    "# e.say('''vinod is chutiya and gandu''')\n",
    "# e.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d6704b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = pyttsx3.init()\n",
    "# voices = engine.getProperty('voices')\n",
    "# for voice in voices:\n",
    "#     print(voice)\n",
    "#     engine.setProperty('voice', voice.id)\n",
    "#     engine.say('vinod is very very chutiya and gandu ladka')\n",
    "# engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a793e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e8aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3949f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a3d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25f0ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dlib\n",
    "# import sys\n",
    "# import cv2\n",
    "# import time\n",
    "# import numpy as np\n",
    "# from scipy.spatial import distance as dist\n",
    "# from threading import Thread\n",
    "# import playsound\n",
    "# #import Queue as queue\n",
    "\n",
    "# import queue\n",
    "# #import Queue\n",
    "# # from light_variability import adjust_gamma\n",
    "\n",
    "# FACE_DOWNSAMPLE_RATIO = 1.5\n",
    "# RESIZE_HEIGHT = 460\n",
    "\n",
    "# thresh = 0.27\n",
    "# modelPath = \"shape_predictor_68_face_landmarks.dat\"\n",
    "# sound_path = \"alarm.wav\"\n",
    "\n",
    "# detector = dlib.get_frontal_face_detector()\n",
    "# predictor = dlib.shape_predictor(modelPath)\n",
    "\n",
    "# leftEyeIndex = [36, 37, 38, 39, 40, 41]\n",
    "# rightEyeIndex = [42, 43, 44, 45, 46, 47]\n",
    "\n",
    "# blinkCount = 0\n",
    "# drowsy = 0\n",
    "# state = 0\n",
    "# blinkTime = 0.15 #150ms\n",
    "# drowsyTime = 1.5  #1200ms\n",
    "# ALARM_ON = False\n",
    "# GAMMA = 1.5\n",
    "# threadStatusQ = queue.Queue()\n",
    "\n",
    "# invGamma = 1.0/GAMMA\n",
    "# table = np.array([((i / 255.0) ** invGamma) * 255 for i in range(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "# def gamma_correction(image):\n",
    "#     return cv2.LUT(image, table)\n",
    "\n",
    "# def histogram_equalization(image):\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     return cv2.equalizeHist(gray) \n",
    "\n",
    "# def soundAlert(path, threadStatusQ):\n",
    "#     while True:\n",
    "#         if not threadStatusQ.empty():\n",
    "#             FINISHED = threadStatusQ.get()\n",
    "#             if FINISHED:\n",
    "#                 break\n",
    "#         playsound.playsound(path)\n",
    "\n",
    "# def eye_aspect_ratio(eye):\n",
    "#     A = dist.euclidean(eye[1], eye[5])\n",
    "#     B = dist.euclidean(eye[2], eye[4])\n",
    "#     C = dist.euclidean(eye[0], eye[3])\n",
    "#     ear = (A + B) / (2.0 * C)\n",
    "\n",
    "#     return ear\n",
    "\n",
    "\n",
    "# def checkEyeStatus(landmarks):\n",
    "#     mask = np.zeros(frame.shape[:2], dtype = np.float32)\n",
    "    \n",
    "#     hullLeftEye = []\n",
    "#     for i in range(0, len(leftEyeIndex)):\n",
    "#         hullLeftEye.append((landmarks[leftEyeIndex[i]][0], landmarks[leftEyeIndex[i]][1]))\n",
    "\n",
    "#     cv2.fillConvexPoly(mask, np.int32(hullLeftEye), 255)\n",
    "\n",
    "#     hullRightEye = []\n",
    "#     for i in range(0, len(rightEyeIndex)):\n",
    "#         hullRightEye.append((landmarks[rightEyeIndex[i]][0], landmarks[rightEyeIndex[i]][1]))\n",
    "\n",
    "\n",
    "#     cv2.fillConvexPoly(mask, np.int32(hullRightEye), 255)\n",
    "\n",
    "#     # lenLeftEyeX = landmarks[leftEyeIndex[3]][0] - landmarks[leftEyeIndex[0]][0]\n",
    "#     # lenLeftEyeY = landmarks[leftEyeIndex[3]][1] - landmarks[leftEyeIndex[0]][1]\n",
    "\n",
    "#     # lenLeftEyeSquared = (lenLeftEyeX ** 2) + (lenLeftEyeY ** 2)\n",
    "#     # eyeRegionCount = cv2.countNonZero(mask)\n",
    "\n",
    "#     # normalizedCount = eyeRegionCount/np.float32(lenLeftEyeSquared)\n",
    "\n",
    "#     #############################################################################\n",
    "#     leftEAR = eye_aspect_ratio(hullLeftEye)\n",
    "#     rightEAR = eye_aspect_ratio(hullRightEye)\n",
    "\n",
    "#     ear = (leftEAR + rightEAR) / 2.0\n",
    "#     #############################################################################\n",
    "\n",
    "#     eyeStatus = 1          # 1 -> Open, 0 -> closed\n",
    "#     if (ear < thresh):\n",
    "#         eyeStatus = 0\n",
    "\n",
    "#     return eyeStatus  \n",
    "\n",
    "# def checkBlinkStatus(eyeStatus):\n",
    "#     global state, blinkCount, drowsy\n",
    "#     if(state >= 0 and state <= falseBlinkLimit):\n",
    "#         if(eyeStatus):\n",
    "#             state = 0\n",
    "\n",
    "#         else:\n",
    "#             state += 1\n",
    "\n",
    "#     elif(state >= falseBlinkLimit and state < drowsyLimit):\n",
    "#         if(eyeStatus):\n",
    "#             blinkCount += 1 \n",
    "#             state = 0\n",
    "\n",
    "#         else:\n",
    "#             state += 1\n",
    "\n",
    "\n",
    "#     else:\n",
    "#         if(eyeStatus):\n",
    "#             state = 0\n",
    "#             drowsy = 1\n",
    "#             blinkCount += 1\n",
    "\n",
    "#         else:\n",
    "#             drowsy = 1\n",
    "\n",
    "# def getLandmarks(im):\n",
    "#     imSmall = cv2.resize(im, None, \n",
    "#                             fx = 1.0/FACE_DOWNSAMPLE_RATIO, \n",
    "#                             fy = 1.0/FACE_DOWNSAMPLE_RATIO, \n",
    "#                             interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "#     rects = detector(imSmall, 0)\n",
    "#     if len(rects) == 0:\n",
    "#         return 0\n",
    "\n",
    "#     newRect = dlib.rectangle(int(rects[0].left() * FACE_DOWNSAMPLE_RATIO),\n",
    "#                             int(rects[0].top() * FACE_DOWNSAMPLE_RATIO),\n",
    "#                             int(rects[0].right() * FACE_DOWNSAMPLE_RATIO),\n",
    "#                             int(rects[0].bottom() * FACE_DOWNSAMPLE_RATIO))\n",
    "\n",
    "#     points = []\n",
    "#     [points.append((p.x, p.y)) for p in predictor(im, newRect).parts()]\n",
    "#     return points\n",
    "\n",
    "# capture = cv2.VideoCapture(0)\n",
    "\n",
    "# for i in range(10):\n",
    "#     ret, frame = capture.read()\n",
    "\n",
    "# totalTime = 0.0\n",
    "# validFrames = 0\n",
    "# dummyFrames = 100\n",
    "\n",
    "# print(\"Caliberation in Progress!\")\n",
    "# while(validFrames < dummyFrames):\n",
    "#     validFrames += 1\n",
    "#     t = time.time()\n",
    "#     ret, frame = capture.read()\n",
    "#     height, width = frame.shape[:2]\n",
    "#     IMAGE_RESIZE = np.float32(height)/RESIZE_HEIGHT\n",
    "#     frame = cv2.resize(frame, None, \n",
    "#                         fx = 1/IMAGE_RESIZE, \n",
    "#                         fy = 1/IMAGE_RESIZE, \n",
    "#                         interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "#     # adjusted = gamma_correction(frame)\n",
    "#     adjusted = histogram_equalization(frame)\n",
    "\n",
    "#     landmarks = getLandmarks(adjusted)\n",
    "#     timeLandmarks = time.time() - t\n",
    "\n",
    "#     if landmarks == 0:\n",
    "#         validFrames -= 1\n",
    "#         cv2.putText(frame, \"Unable to detect face, Please check proper lighting\", (10, 30), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#         cv2.putText(frame, \"or decrease FACE_DOWNSAMPLE_RATIO\", (10, 50), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#         cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "#         if cv2.waitKey(1) & 0xFF == 27:\n",
    "#             sys.exit()\n",
    "\n",
    "#     else:\n",
    "#         totalTime += timeLandmarks\n",
    "#         # cv2.putText(frame, \"Caliberation in Progress\", (200, 30), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#         # cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "        \n",
    "#     # if cv2.waitKey(1) & 0xFF == 27:\n",
    "#     #         sys.exit()\n",
    "\n",
    "# print(\"Caliberation Complete!\")\n",
    "\n",
    "# spf = totalTime/dummyFrames\n",
    "# print(\"Current SPF (seconds per frame) is {:.2f} ms\".format(spf * 1000))\n",
    "\n",
    "# drowsyLimit = drowsyTime/spf\n",
    "# falseBlinkLimit = blinkTime/spf\n",
    "# print(\"drowsy limit: {}, false blink limit: {}\".format(drowsyLimit, falseBlinkLimit))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     vid_writer = cv2.VideoWriter('output-low-light-2.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame.shape[1],frame.shape[0]))\n",
    "#     while(1):\n",
    "#         try:\n",
    "#             t = time.time()\n",
    "#             ret, frame = capture.read()\n",
    "#             height, width = frame.shape[:2]\n",
    "#             IMAGE_RESIZE = np.float32(height)/RESIZE_HEIGHT\n",
    "#             frame = cv2.resize(frame, None, \n",
    "#                                 fx = 1/IMAGE_RESIZE, \n",
    "#                                 fy = 1/IMAGE_RESIZE, \n",
    "#                                 interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "#             # adjusted = gamma_correction(frame)\n",
    "#             adjusted = histogram_equalization(frame)\n",
    "\n",
    "#             landmarks = getLandmarks(adjusted)\n",
    "#             if landmarks == 0:\n",
    "#                 validFrames -= 1\n",
    "#                 cv2.putText(frame, \"Unable to detect face, Please check proper lighting\", (10, 30), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#                 cv2.putText(frame, \"or decrease FACE_DOWNSAMPLE_RATIO\", (10, 50), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#                 cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "#                 if cv2.waitKey(1) & 0xFF == 27:\n",
    "#                     break\n",
    "#                 continue\n",
    "\n",
    "#             eyeStatus = checkEyeStatus(landmarks)\n",
    "#             checkBlinkStatus(eyeStatus)\n",
    "\n",
    "#             for i in range(0, len(leftEyeIndex)):\n",
    "#                 cv2.circle(frame, (landmarks[leftEyeIndex[i]][0], landmarks[leftEyeIndex[i]][1]), 1, (0, 0, 255), -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "#             for i in range(0, len(rightEyeIndex)):\n",
    "#                 cv2.circle(frame, (landmarks[rightEyeIndex[i]][0], landmarks[rightEyeIndex[i]][1]), 1, (0, 0, 255), -1, lineType=cv2.LINE_AA)\n",
    "\n",
    "#             if drowsy:\n",
    "#                 cv2.putText(frame, \"! ! ! DROWSINESS ALERT ! ! !\", (70, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "#                 if not ALARM_ON:\n",
    "#                     ALARM_ON = True\n",
    "#                     threadStatusQ.put(not ALARM_ON)\n",
    "#                     thread = Thread(target=soundAlert, args=(sound_path, threadStatusQ,))\n",
    "#                     thread.setDaemon(True)\n",
    "#                     thread.start()\n",
    "\n",
    "#             else:\n",
    "#                 cv2.putText(frame, \"Blinks : {}\".format(blinkCount), (460, 80), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 2, cv2.LINE_AA)\n",
    "#                 # (0, 400)\n",
    "#                 ALARM_ON = False\n",
    "\n",
    "\n",
    "#             cv2.imshow(\"Blink Detection Demo\", frame)\n",
    "#             vid_writer.write(frame)\n",
    "\n",
    "#             k = cv2.waitKey(1) \n",
    "#             if k == ord('r'):\n",
    "#                 state = 0\n",
    "#                 drowsy = 0\n",
    "#                 ALARM_ON = False\n",
    "#                 threadStatusQ.put(not ALARM_ON)\n",
    "\n",
    "#             elif k == 27:\n",
    "#                 break\n",
    "\n",
    "#             # print(\"Time taken\", time.time() - t)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             break\n",
    "\n",
    "#     capture.release()\n",
    "#     vid_writer.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7098db61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
